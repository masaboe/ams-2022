{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "usduAw6FdJxE"
   },
   "source": [
    "<img src=\"https://2.bp.blogspot.com/-066qpJs0Ttc/WiYPXGNYEYI/AAAAAAAAFu8/XbOaf7DqfDMM9truu3DkrkIGfRgP4zBzgCLcBGAs/s1600/udinus.jpg\"  width=\"200\">\n",
    "\n",
    "# AMS - QA System\n",
    "\n",
    "oleh: Dr. Eng. Farrikh Alzami M.Kom; Abu Salam, M.Kom\n",
    "\n",
    "disini kita akan belajar menggunakan modul:\n",
    "\n",
    "dataset: (COVID19_wikipedia article.txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 32289,
     "status": "ok",
     "timestamp": 1668921918912,
     "user": {
      "displayName": "farrikh alzami",
      "userId": "11964535993149439504"
     },
     "user_tz": -420
    },
    "id": "_Lkfb64rfuca",
    "outputId": "2eaa63b8-5d3c-4061-9231-80b091626de6"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# import sys\n",
    "# sys.path.append('/content/drive/My Drive/Colab Notebooks/AMS2023')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/Users/masaboe/Documents/NGAJAR/2022/Ganjil 2/AMS-SI/Materi/Lab/questionAnswering')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pathlib\n",
    "pathlib.Path().resolve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 54866,
     "status": "ok",
     "timestamp": 1668921977846,
     "user": {
      "displayName": "farrikh alzami",
      "userId": "11964535993149439504"
     },
     "user_tz": -420
    },
    "id": "5ArZ7hoVk0-Z",
    "outputId": "5987e7e2-fbae-4e20-b335-1368e4447b97"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading collection 'all'\n",
      "[nltk_data]    | \n",
      "[nltk_data]    | Downloading package abc to\n",
      "[nltk_data]    |     /Users/masaboe/nltk_data...\n",
      "[nltk_data]    |   Package abc is already up-to-date!\n",
      "[nltk_data]    | Downloading package alpino to\n",
      "[nltk_data]    |     /Users/masaboe/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/alpino.zip.\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]    |     /Users/masaboe/nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
      "[nltk_data]    |       to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n",
      "[nltk_data]    |     /Users/masaboe/nltk_data...\n",
      "[nltk_data]    |   Unzipping\n",
      "[nltk_data]    |       taggers/averaged_perceptron_tagger_ru.zip.\n",
      "[nltk_data]    | Downloading package basque_grammars to\n",
      "[nltk_data]    |     /Users/masaboe/nltk_data...\n",
      "[nltk_data]    |   Unzipping grammars/basque_grammars.zip.\n",
      "[nltk_data]    | Downloading package bcp47 to\n",
      "[nltk_data]    |     /Users/masaboe/nltk_data...\n",
      "[nltk_data]    | Downloading package biocreative_ppi to\n",
      "[nltk_data]    |     /Users/masaboe/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/biocreative_ppi.zip.\n",
      "[nltk_data]    | Downloading package bllip_wsj_no_aux to\n",
      "[nltk_data]    |     /Users/masaboe/nltk_data...\n",
      "[nltk_data]    |   Unzipping models/bllip_wsj_no_aux.zip.\n",
      "[nltk_data]    | Downloading package book_grammars to\n",
      "[nltk_data]    |     /Users/masaboe/nltk_data...\n",
      "[nltk_data]    |   Package book_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package brown to\n",
      "[nltk_data]    |     /Users/masaboe/nltk_data...\n",
      "[nltk_data]    |   Package brown is already up-to-date!\n",
      "[nltk_data]    | Downloading package brown_tei to\n",
      "[nltk_data]    |     /Users/masaboe/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/brown_tei.zip.\n",
      "[nltk_data]    | Downloading package cess_cat to\n",
      "[nltk_data]    |     /Users/masaboe/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/cess_cat.zip.\n",
      "[nltk_data]    | Downloading package cess_esp to\n",
      "[nltk_data]    |     /Users/masaboe/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/cess_esp.zip.\n",
      "[nltk_data]    | Downloading package chat80 to\n",
      "[nltk_data]    |     /Users/masaboe/nltk_data...\n",
      "[nltk_data]    |   Package chat80 is already up-to-date!\n",
      "[nltk_data]    | Downloading package city_database to\n",
      "[nltk_data]    |     /Users/masaboe/nltk_data...\n",
      "[nltk_data]    |   Package city_database is already up-to-date!\n",
      "[nltk_data]    | Downloading package cmudict to\n",
      "[nltk_data]    |     /Users/masaboe/nltk_data...\n",
      "[nltk_data]    |   Package cmudict is already up-to-date!\n",
      "[nltk_data]    | Downloading package comparative_sentences to\n",
      "[nltk_data]    |     /Users/masaboe/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/comparative_sentences.zip.\n",
      "[nltk_data]    | Downloading package comtrans to\n",
      "[nltk_data]    |     /Users/masaboe/nltk_data...\n",
      "[nltk_data]    | Downloading package conll2000 to\n",
      "[nltk_data]    |     /Users/masaboe/nltk_data...\n",
      "[nltk_data]    |   Package conll2000 is already up-to-date!\n",
      "[nltk_data]    | Downloading package conll2002 to\n",
      "[nltk_data]    |     /Users/masaboe/nltk_data...\n",
      "[nltk_data]    |   Package conll2002 is already up-to-date!\n",
      "[nltk_data]    | Downloading package conll2007 to\n",
      "[nltk_data]    |     /Users/masaboe/nltk_data...\n",
      "[nltk_data]    | Downloading package crubadan to\n",
      "[nltk_data]    |     /Users/masaboe/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/crubadan.zip.\n",
      "[nltk_data]    | Downloading package dependency_treebank to\n",
      "[nltk_data]    |     /Users/masaboe/nltk_data...\n",
      "[nltk_data]    |   Package dependency_treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package dolch to\n",
      "[nltk_data]    |     /Users/masaboe/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/dolch.zip.\n",
      "[nltk_data]    | Downloading package europarl_raw to\n",
      "[nltk_data]    |     /Users/masaboe/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/europarl_raw.zip.\n",
      "[nltk_data]    | Downloading package extended_omw to\n",
      "[nltk_data]    |     /Users/masaboe/nltk_data...\n",
      "[nltk_data]    | Downloading package floresta to\n",
      "[nltk_data]    |     /Users/masaboe/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/floresta.zip.\n",
      "[nltk_data]    | Downloading package framenet_v15 to\n",
      "[nltk_data]    |     /Users/masaboe/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/framenet_v15.zip.\n",
      "[nltk_data]    | Downloading package framenet_v17 to\n",
      "[nltk_data]    |     /Users/masaboe/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/framenet_v17.zip.\n",
      "[nltk_data]    | Downloading package gazetteers to\n",
      "[nltk_data]    |     /Users/masaboe/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/gazetteers.zip.\n",
      "[nltk_data]    | Downloading package genesis to\n",
      "[nltk_data]    |     /Users/masaboe/nltk_data...\n",
      "[nltk_data]    |   Package genesis is already up-to-date!\n",
      "[nltk_data]    | Downloading package gutenberg to\n",
      "[nltk_data]    |     /Users/masaboe/nltk_data...\n",
      "[nltk_data]    |   Package gutenberg is already up-to-date!\n",
      "[nltk_data]    | Downloading package ieer to\n",
      "[nltk_data]    |     /Users/masaboe/nltk_data...\n",
      "[nltk_data]    |   Package ieer is already up-to-date!\n",
      "[nltk_data]    | Downloading package inaugural to\n",
      "[nltk_data]    |     /Users/masaboe/nltk_data...\n",
      "[nltk_data]    |   Package inaugural is already up-to-date!\n",
      "[nltk_data]    | Downloading package indian to\n",
      "[nltk_data]    |     /Users/masaboe/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/indian.zip.\n",
      "[nltk_data]    | Downloading package jeita to\n",
      "[nltk_data]    |     /Users/masaboe/nltk_data...\n",
      "[nltk_data]    | Downloading package kimmo to\n",
      "[nltk_data]    |     /Users/masaboe/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/kimmo.zip.\n",
      "[nltk_data]    | Downloading package knbc to\n",
      "[nltk_data]    |     /Users/masaboe/nltk_data...\n",
      "[nltk_data]    | Downloading package large_grammars to\n",
      "[nltk_data]    |     /Users/masaboe/nltk_data...\n",
      "[nltk_data]    |   Unzipping grammars/large_grammars.zip.\n",
      "[nltk_data]    | Downloading package lin_thesaurus to\n",
      "[nltk_data]    |     /Users/masaboe/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/lin_thesaurus.zip.\n",
      "[nltk_data]    | Downloading package mac_morpho to\n",
      "[nltk_data]    |     /Users/masaboe/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/mac_morpho.zip.\n",
      "[nltk_data]    | Downloading package machado to\n",
      "[nltk_data]    |     /Users/masaboe/nltk_data...\n",
      "[nltk_data]    | Downloading package masc_tagged to\n",
      "[nltk_data]    |     /Users/masaboe/nltk_data...\n",
      "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
      "[nltk_data]    |     /Users/masaboe/nltk_data...\n",
      "[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
      "[nltk_data]    |     /Users/masaboe/nltk_data...\n",
      "[nltk_data]    |   Package maxent_treebank_pos_tagger is already up-\n",
      "[nltk_data]    |       to-date!\n",
      "[nltk_data]    | Downloading package moses_sample to\n",
      "[nltk_data]    |     /Users/masaboe/nltk_data...\n",
      "[nltk_data]    |   Unzipping models/moses_sample.zip.\n",
      "[nltk_data]    | Downloading package movie_reviews to\n",
      "[nltk_data]    |     /Users/masaboe/nltk_data...\n",
      "[nltk_data]    |   Package movie_reviews is already up-to-date!\n",
      "[nltk_data]    | Downloading package mte_teip5 to\n",
      "[nltk_data]    |     /Users/masaboe/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/mte_teip5.zip.\n",
      "[nltk_data]    | Downloading package mwa_ppdb to\n",
      "[nltk_data]    |     /Users/masaboe/nltk_data...\n",
      "[nltk_data]    |   Unzipping misc/mwa_ppdb.zip.\n",
      "[nltk_data]    | Downloading package names to\n",
      "[nltk_data]    |     /Users/masaboe/nltk_data...\n",
      "[nltk_data]    |   Package names is already up-to-date!\n",
      "[nltk_data]    | Downloading package nombank.1.0 to\n",
      "[nltk_data]    |     /Users/masaboe/nltk_data...\n",
      "[nltk_data]    | Downloading package nonbreaking_prefixes to\n",
      "[nltk_data]    |     /Users/masaboe/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/nonbreaking_prefixes.zip.\n",
      "[nltk_data]    | Downloading package nps_chat to\n",
      "[nltk_data]    |     /Users/masaboe/nltk_data...\n",
      "[nltk_data]    |   Package nps_chat is already up-to-date!\n",
      "[nltk_data]    | Downloading package omw to\n",
      "[nltk_data]    |     /Users/masaboe/nltk_data...\n",
      "[nltk_data]    | Downloading package omw-1.4 to\n",
      "[nltk_data]    |     /Users/masaboe/nltk_data...\n",
      "[nltk_data]    |   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data]    | Downloading package opinion_lexicon to\n",
      "[nltk_data]    |     /Users/masaboe/nltk_data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data]    |   Unzipping corpora/opinion_lexicon.zip.\n",
      "[nltk_data]    | Downloading package panlex_swadesh to\n",
      "[nltk_data]    |     /Users/masaboe/nltk_data...\n",
      "[nltk_data]    |   Package panlex_swadesh is already up-to-date!\n",
      "[nltk_data]    | Downloading package paradigms to\n",
      "[nltk_data]    |     /Users/masaboe/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/paradigms.zip.\n",
      "[nltk_data]    | Downloading package pe08 to\n",
      "[nltk_data]    |     /Users/masaboe/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/pe08.zip.\n",
      "[nltk_data]    | Downloading package perluniprops to\n",
      "[nltk_data]    |     /Users/masaboe/nltk_data...\n",
      "[nltk_data]    |   Unzipping misc/perluniprops.zip.\n",
      "[nltk_data]    | Downloading package pil to\n",
      "[nltk_data]    |     /Users/masaboe/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/pil.zip.\n",
      "[nltk_data]    | Downloading package pl196x to\n",
      "[nltk_data]    |     /Users/masaboe/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/pl196x.zip.\n",
      "[nltk_data]    | Downloading package porter_test to\n",
      "[nltk_data]    |     /Users/masaboe/nltk_data...\n",
      "[nltk_data]    |   Unzipping stemmers/porter_test.zip.\n",
      "[nltk_data]    | Downloading package ppattach to\n",
      "[nltk_data]    |     /Users/masaboe/nltk_data...\n",
      "[nltk_data]    |   Package ppattach is already up-to-date!\n",
      "[nltk_data]    | Downloading package problem_reports to\n",
      "[nltk_data]    |     /Users/masaboe/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/problem_reports.zip.\n",
      "[nltk_data]    | Downloading package product_reviews_1 to\n",
      "[nltk_data]    |     /Users/masaboe/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/product_reviews_1.zip.\n",
      "[nltk_data]    | Downloading package product_reviews_2 to\n",
      "[nltk_data]    |     /Users/masaboe/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/product_reviews_2.zip.\n",
      "[nltk_data]    | Downloading package propbank to\n",
      "[nltk_data]    |     /Users/masaboe/nltk_data...\n",
      "[nltk_data]    | Downloading package pros_cons to\n",
      "[nltk_data]    |     /Users/masaboe/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/pros_cons.zip.\n",
      "[nltk_data]    | Downloading package ptb to\n",
      "[nltk_data]    |     /Users/masaboe/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/ptb.zip.\n",
      "[nltk_data]    | Downloading package punkt to\n",
      "[nltk_data]    |     /Users/masaboe/nltk_data...\n",
      "[nltk_data]    |   Package punkt is already up-to-date!\n",
      "[nltk_data]    | Downloading package qc to /Users/masaboe/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/qc.zip.\n",
      "[nltk_data]    | Downloading package reuters to\n",
      "[nltk_data]    |     /Users/masaboe/nltk_data...\n",
      "[nltk_data]    |   Package reuters is already up-to-date!\n",
      "[nltk_data]    | Downloading package rslp to\n",
      "[nltk_data]    |     /Users/masaboe/nltk_data...\n",
      "[nltk_data]    |   Unzipping stemmers/rslp.zip.\n",
      "[nltk_data]    | Downloading package rte to\n",
      "[nltk_data]    |     /Users/masaboe/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/rte.zip.\n",
      "[nltk_data]    | Downloading package sample_grammars to\n",
      "[nltk_data]    |     /Users/masaboe/nltk_data...\n",
      "[nltk_data]    |   Unzipping grammars/sample_grammars.zip.\n",
      "[nltk_data]    | Downloading package semcor to\n",
      "[nltk_data]    |     /Users/masaboe/nltk_data...\n",
      "[nltk_data]    | Downloading package senseval to\n",
      "[nltk_data]    |     /Users/masaboe/nltk_data...\n",
      "[nltk_data]    |   Package senseval is already up-to-date!\n",
      "[nltk_data]    | Downloading package sentence_polarity to\n",
      "[nltk_data]    |     /Users/masaboe/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/sentence_polarity.zip.\n",
      "[nltk_data]    | Downloading package sentiwordnet to\n",
      "[nltk_data]    |     /Users/masaboe/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/sentiwordnet.zip.\n",
      "[nltk_data]    | Downloading package shakespeare to\n",
      "[nltk_data]    |     /Users/masaboe/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/shakespeare.zip.\n",
      "[nltk_data]    | Downloading package sinica_treebank to\n",
      "[nltk_data]    |     /Users/masaboe/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/sinica_treebank.zip.\n",
      "[nltk_data]    | Downloading package smultron to\n",
      "[nltk_data]    |     /Users/masaboe/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/smultron.zip.\n",
      "[nltk_data]    | Downloading package snowball_data to\n",
      "[nltk_data]    |     /Users/masaboe/nltk_data...\n",
      "[nltk_data]    | Downloading package spanish_grammars to\n",
      "[nltk_data]    |     /Users/masaboe/nltk_data...\n",
      "[nltk_data]    |   Unzipping grammars/spanish_grammars.zip.\n",
      "[nltk_data]    | Downloading package state_union to\n",
      "[nltk_data]    |     /Users/masaboe/nltk_data...\n",
      "[nltk_data]    |   Package state_union is already up-to-date!\n",
      "[nltk_data]    | Downloading package stopwords to\n",
      "[nltk_data]    |     /Users/masaboe/nltk_data...\n",
      "[nltk_data]    |   Package stopwords is already up-to-date!\n",
      "[nltk_data]    | Downloading package subjectivity to\n",
      "[nltk_data]    |     /Users/masaboe/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/subjectivity.zip.\n",
      "[nltk_data]    | Downloading package swadesh to\n",
      "[nltk_data]    |     /Users/masaboe/nltk_data...\n",
      "[nltk_data]    |   Package swadesh is already up-to-date!\n",
      "[nltk_data]    | Downloading package switchboard to\n",
      "[nltk_data]    |     /Users/masaboe/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/switchboard.zip.\n",
      "[nltk_data]    | Downloading package tagsets to\n",
      "[nltk_data]    |     /Users/masaboe/nltk_data...\n",
      "[nltk_data]    |   Package tagsets is already up-to-date!\n",
      "[nltk_data]    | Downloading package timit to\n",
      "[nltk_data]    |     /Users/masaboe/nltk_data...\n",
      "[nltk_data]    |   Package timit is already up-to-date!\n",
      "[nltk_data]    | Downloading package toolbox to\n",
      "[nltk_data]    |     /Users/masaboe/nltk_data...\n",
      "[nltk_data]    |   Package toolbox is already up-to-date!\n",
      "[nltk_data]    | Downloading package treebank to\n",
      "[nltk_data]    |     /Users/masaboe/nltk_data...\n",
      "[nltk_data]    |   Package treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package twitter_samples to\n",
      "[nltk_data]    |     /Users/masaboe/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/twitter_samples.zip.\n",
      "[nltk_data]    | Downloading package udhr to\n",
      "[nltk_data]    |     /Users/masaboe/nltk_data...\n",
      "[nltk_data]    |   Package udhr is already up-to-date!\n",
      "[nltk_data]    | Downloading package udhr2 to\n",
      "[nltk_data]    |     /Users/masaboe/nltk_data...\n",
      "[nltk_data]    |   Package udhr2 is already up-to-date!\n",
      "[nltk_data]    | Downloading package unicode_samples to\n",
      "[nltk_data]    |     /Users/masaboe/nltk_data...\n",
      "[nltk_data]    |   Package unicode_samples is already up-to-date!\n",
      "[nltk_data]    | Downloading package universal_tagset to\n",
      "[nltk_data]    |     /Users/masaboe/nltk_data...\n",
      "[nltk_data]    |   Package universal_tagset is already up-to-date!\n",
      "[nltk_data]    | Downloading package universal_treebanks_v20 to\n",
      "[nltk_data]    |     /Users/masaboe/nltk_data...\n",
      "[nltk_data]    | Downloading package vader_lexicon to\n",
      "[nltk_data]    |     /Users/masaboe/nltk_data...\n",
      "[nltk_data]    | Downloading package verbnet to\n",
      "[nltk_data]    |     /Users/masaboe/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/verbnet.zip.\n",
      "[nltk_data]    | Downloading package verbnet3 to\n",
      "[nltk_data]    |     /Users/masaboe/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/verbnet3.zip.\n",
      "[nltk_data]    | Downloading package webtext to\n",
      "[nltk_data]    |     /Users/masaboe/nltk_data...\n",
      "[nltk_data]    |   Package webtext is already up-to-date!\n",
      "[nltk_data]    | Downloading package wmt15_eval to\n",
      "[nltk_data]    |     /Users/masaboe/nltk_data...\n",
      "[nltk_data]    |   Unzipping models/wmt15_eval.zip.\n",
      "[nltk_data]    | Downloading package word2vec_sample to\n",
      "[nltk_data]    |     /Users/masaboe/nltk_data...\n",
      "[nltk_data]    |   Unzipping models/word2vec_sample.zip.\n",
      "[nltk_data]    | Downloading package wordnet to\n",
      "[nltk_data]    |     /Users/masaboe/nltk_data...\n",
      "[nltk_data]    |   Package wordnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet2021 to\n",
      "[nltk_data]    |     /Users/masaboe/nltk_data...\n",
      "[nltk_data]    | Downloading package wordnet31 to\n",
      "[nltk_data]    |     /Users/masaboe/nltk_data...\n",
      "[nltk_data]    | Downloading package wordnet_ic to\n",
      "[nltk_data]    |     /Users/masaboe/nltk_data...\n",
      "[nltk_data]    |   Package wordnet_ic is already up-to-date!\n",
      "[nltk_data]    | Downloading package words to\n",
      "[nltk_data]    |     /Users/masaboe/nltk_data...\n",
      "[nltk_data]    |   Package words is already up-to-date!\n",
      "[nltk_data]    | Downloading package ycoe to\n",
      "[nltk_data]    |     /Users/masaboe/nltk_data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data]    |   Unzipping corpora/ycoe.zip.\n",
      "[nltk_data]    | \n",
      "[nltk_data]  Done downloading collection all\n",
      "[nltk_data] Downloading package punkt to /Users/masaboe/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/masaboe/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#importing the required packages\n",
    "import nltk\n",
    "#### Run it, if before never download nltk library\n",
    "# nltk.download('all')\n",
    "import re\n",
    "import string\n",
    "import gensim \n",
    "from gensim.parsing.preprocessing import remove_stopwords\n",
    "from nltk import sent_tokenize, word_tokenize\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy import spatial\n",
    "from nltk import pos_tag,word_tokenize,ne_chunk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from pandas import DataFrame\n",
    "\n",
    "from nltk.corpus import wordnet,stopwords\n",
    "import spacy\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eX8Y2H02dwAC"
   },
   "source": [
    "**Uploading the Reference Article**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ce46MqrGf_Z_"
   },
   "outputs": [],
   "source": [
    "#sample = '/content/drive/My Drive/Colab Notebooks/AMS2023/COVID19_wikipedia article.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "N3kTgL0Qk6tn"
   },
   "outputs": [],
   "source": [
    "# from google.colab import files\n",
    "# uploaded=files.upload()\n",
    "sample = open(\"/Users/masaboe/Documents/NGAJAR/2022/Ganjil 2/AMS-SI/Materi/Lab/questionAnswering/COVID19_wikipedia article.txt\", \"r\") \n",
    "\n",
    "s = sample.read() \n",
    "s=s.replace(\"COVID 19\",\"coronavirus\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 127
    },
    "executionInfo": {
     "elapsed": 325,
     "status": "ok",
     "timestamp": 1668922074740,
     "user": {
      "displayName": "farrikh alzami",
      "userId": "11964535993149439504"
     },
     "user_tz": -420
    },
    "id": "0nUC_lZHgdxP",
    "outputId": "44a9e7bf-7b23-4709-9b2e-fdb45f5a7f20"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'It was first identified in December 2019 in Wuhan, China, and has resulted in an ongoing pandemic. The first confirmed case has been traced back to 17th November 2019. Traces of the virus have been found in December-2019 wastewater that was collected from Milan and Turin. As of 21 June 2020, more than 8.75 million cases have been reported across 188 countries and territories, resulting in more than 463,000 deaths. More than 4.33 million people have recovered. \\nCommon symptoms include fever, cough, fatigue, shortness of breath, and loss of smell and taste. While the majority of cases result in mild symptoms, some progress to acute respiratory distress syndrome (ARDS) possibly precipitated by cytokine storm, multi-organ failure, septic shock, and blood clots. The time from exposure to onset of symptoms is typically around five days, but may range from two to fourteen days. \\nThe virus is primarily spread between people during close contact, most often via small droplets produced by coughing, sneezing, and talking. The droplets usually fall to the ground or onto surfaces rather than travelling through air over long distances. However, research as of June 2020 has shown that speech-generated droplets may remain airborne for tens of minutes. Less commonly, people may become infected by touching a contaminated surface and then touching their face. It is most contagious during the first three days after the onset of symptoms, although spread is possible before symptoms appear, and from people who do not show symptoms. The standard method of diagnosis is by real-time reverse transcription polymerase chain reaction (rRT-PCR) from a nasopharyngeal swab. Chest CT imaging may also be helpful for diagnosis in individuals where there is a high suspicion of infection based on symptoms and risk factors; however, guidelines do not recommend using CT imaging for routine screening. \\nRecommended measures to prevent infection include frequent hand washing, maintaining physical distance from others (especially from those with symptoms), quarantine (especially for those with symptoms), covering coughs, and keeping unwashed hands away from the face. The use of cloth face coverings such as a scarf or a bandana has been recommended by health officials in public settings to minimise the risk of transmissions, with some authorities requiring their use. Health officials also stated that medical-grade face masks, such as N95 masks, should only be used by healthcare workers, first responders, and those who directly care for infected individuals.\\nAccording to the World Health Organization (WHO), there are no vaccines nor specific antiviral treatments for COVID-19. Management involves the treatment of symptoms, supportive care, isolation, and experimental measures. The World Health Organization (WHO) declared the coronavirus outbreak a public health emergency of international concern (PHEIC) on 30 January 2020 and a pandemic on 11 March 2020. Local transmission of the disease has occurred in most countries across all six WHO regions. \\nPreventive measures to reduce the chances of infection include staying at home, avoiding crowded places, keeping distance from others, washing hands with soap and water often and for at least 20 seconds, practising good respiratory hygiene, and avoiding touching the eyes, nose, or mouth with unwashed hands. The U.S. Centers for Disease Control and Prevention (CDC) recommends covering the mouth and nose with a tissue when coughing or sneezing and recommends using the inside of the elbow if no tissue is available. Proper hand hygiene after any cough or sneeze is encouraged. The CDC has recommended cloth face coverings in public settings where other social distancing measures are difficult to maintain, in part to limit transmission by asymptomatic individuals. The U.S. National Institutes of Health guidelines do not recommend any medication for prevention of coronavirus, before or after exposure to the SARS-CoV-2 virus, outside the setting of a clinical trial. \\nSocial distancing strategies aim to reduce contact of infected persons with large groups by closing schools and workplaces, restricting travel, and cancelling large public gatherings. Distancing guidelines also include that people stay at least 6 feet (1.8 m) apart. There is no medication known to be effective at preventing coronavirus. After the implementation of social distancing and stay-at-home orders, many regions have been able to sustain an effective transmission rate (\"Rt\") of less than one, meaning the disease is in remission in those areas. \\nAs a COVID-19 vaccine is not expected until 2021 at the earliest, a key part of managing coronavirus is trying to decrease and delay the epidemic peak, known as \"flattening the curve\".This is done by slowing the infection rate to decrease the risk of health services being overwhelmed, allowing for better treatment of current cases, and delaying additional cases until effective treatments or a vaccine become available. \\nSeveral countries have recommended that healthy individuals wear face masks or cloth face coverings (like scarves or bandanas) at least in certain public settings, including China, Hong Kong, Spain, Italy, Russia, and the United States. This recommendation is meant to reduce the spread of the disease by asymptomatic and pre-symtomatic individuals and is a complementary measure to established preventive measures such as social distancing. Face coverings minimise the excretion of respiratory droplets by infected individuals while breathing, talking and coughing. Non-medical cloth face coverings such as a scarf or a bandana are recommended for the general public in places where social distancing is difficult to maintain. Medical grade facemasks such as N95 masks should be reserved and prioritised for healthcare workers and first responders. \\nThose diagnosed with coronavirus or who believe they may be infected are advised by the CDC to stay home except to get medical care, call ahead before visiting a healthcare provider, wear a face mask before entering the healthcare provider\\'s office and when in any room or vehicle with another person, cover coughs and sneezes with a tissue, regularly wash hands with soap and water and avoid sharing personal household items. The CDC also recommends that individuals wash hands often with soap and water for at least 20 seconds, especially after going to the toilet or when hands are visibly dirty, before eating and after blowing one\\'s nose, coughing or sneezing. It further recommends using an alcohol-based hand sanitiser with at least 60% alcohol, but only when soap and water are not readily available. \\nFor areas where commercial hand sanitisers are not readily available, the WHO provides two formulations for local production. In these formulations, the antimicrobial activity arises from ethanol or isopropanol. Hydrogen peroxide is used to help eliminate bacterial spores in the alcohol; it is \"not an active substance for hand antisepsis\". Glycerol is added as a humectant.\\nFever is the most common symptom of COVID-19, but is highly variable in severity and presentation, with some older, immunocompromised, or critically ill people not having fever at all. In one study, only 44% of people had fever when they presented to the hospital, while 89% went on to develop fever at some point during their hospitalization. A lack of fever does not verify someone is disease free.\\nOther common symptoms include cough, loss of appetite, fatigue, shortness of breath, sputum production, and muscle and joint pains. Symptoms such as nausea, vomiting, and diarrhoea have been observed in varying percentages. Less common symptoms include sneezing, runny nose, sore throat, and skin lesions. Some cases in China initially presented with only chest tightness and palpitations. A decreased sense of smell or disturbances in taste may occur. Loss of smell was a presenting symptom in 30% of confirmed cases in South Korea. \\nAs is common with infections, there is a delay between the moment a person is first infected and the time he or she develops symptoms. This is called the incubation period. The typical incubation period for coronavirus is five or six days, but it can range from one to fourteen days with approximately ten percent of cases taking longer. \\nAn early key to the diagnosis is the tempo of the illness. Early symptoms may include a wide variety of symptoms but infrequently involves shortness of breath. Shortness of breath usually develops several days after initial symptoms. Shortness of breath that begins immediately along with fever and cough is more likely to be anxiety than COVID-19. The most critical days of illness tend to be those following the development of shortness of breath. \\nA minority of cases do not develop noticeable symptoms at any point in time. These asymptomatic carriers tend not to get tested, and their role in transmission is not fully known. Preliminary evidence suggested they may contribute to the spread of the disease. In June 2020, a spokeswoman of WHO said that asymptomatic transmission appears to be \"rare,\" but the evidence for the claim was not released. The next day, WHO clarified that they had intended a narrow definition of \"asymptomatic\" that did not include pre-symptomatic or paucisymptomatic (weak symptoms) transmission and that up to 41% of transmission may be asymptomatic. Transmission without symptoms does occur. \\nCOVID-19 spreads primarily when people are in close contact and one person inhales small droplets produced by an infected person (symptomatic or not) coughing, sneezing, talking, or singing. The WHO recommends 1 metre (3 ft) of social distance; the U.S. CDC recommends 2 metres (6 ft). People can transmit the virus without showing symptoms, but it is unclear how often this happens. One estimate of the number of those infected who are asymptomatic is 40%.\\nPeople are most infectious when they show symptoms (even mild or non-specific symptoms), but may be infectious for up to two days before symptoms appear (pre-symptomatic transmission). They remain infectious an estimated seven to twelve days in moderate cases and an average of two weeks in severe cases. \\nWhen the contaminated droplets fall to floors or surfaces they can, though less commonly, remain infectious if people touch contaminated surfaces and then their eyes, nose or mouth with unwashed hands. On surfaces the amount of active virus decreases over time until it can no longer cause infection, and surfaces are thought not to be the main way the virus spreads. It is unknown what amount of virus on surfaces is required to cause infection via this method, but it can be detected for up to four hours on copper, up to one day on cardboard, and up to three days on plastic (polypropylene) and stainless steel (AISI 304). Surfaces are easily decontaminated with household disinfectants which kill the virus outside the human body or on the hands. Disinfectants or bleach are not a treatment for coronavirus, and cause health problems when not used properly, such as when used inside the human body. \\nThe first case of coronavirus at Delhi was confirmed on 2nd March when a 45 years old person from East Delhi, with a history of travel from Italy, has been tested to be positive for COVID-19. Total 92 contacts of Delhi index case have been traced. Out of these 92 contacts 14 belong to Delhi and rest 74 contacts have been cross notified to respective states. Out of 14 contacts two were symptomatic and found negative for COVID-19. \\n\\n\\n\\n\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WCo5W9nCd9Pl"
   },
   "source": [
    "**Text Preprocessing Functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "zNjJvOtSk7bs"
   },
   "outputs": [],
   "source": [
    "def stem_sentence(sentence):\n",
    "  words=word_tokenize(sentence)\n",
    "  #lemmatizer = WordNetLemmatizer()\n",
    "  \n",
    "  \n",
    "  stemmer = SnowballStemmer(\"english\")\n",
    "  new_words=[]\n",
    "  for i in words:\n",
    "    new_words.append(stemmer.stem(i))\n",
    "    new_words.append(\" \")\n",
    "  return \"\".join(new_words)  \n",
    "  \n",
    "\n",
    "\n",
    "def clean_sentence(sentence, stopwords=True):\n",
    "    \n",
    "    sentence = sentence.lower().strip()\n",
    "    sentence = re.sub(r'[^a-z0-9\\s]', '', sentence)\n",
    "    \n",
    "    \n",
    "    \n",
    "    if stopwords:\n",
    "         sentence = remove_stopwords(sentence)\n",
    "    \n",
    "   \n",
    "    \n",
    "    return sentence\n",
    "def get_cleaned_sentences(sents,stopwords=True):    \n",
    "    \n",
    "    cleaned_sentences=[]\n",
    "\n",
    "    for i in sents:\n",
    "        \n",
    "        cleaning=clean_sentence(i,stopwords)\n",
    "        cleaned=stem_sentence(cleaning)\n",
    "        cleaned_sentences.append(cleaned)\n",
    "    return cleaned_sentences\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UKROOQz6edpa"
   },
   "source": [
    "**create_document_term_matrix: Function to create TF - IDF Matrix**\n",
    "\n",
    "\n",
    "**calculate_cosine_similarity: Function to return the top 3 sentences based on cosine similarity between TF-IDF scores**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DrfY_71UeRcg"
   },
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "RFQbswivlAlp"
   },
   "outputs": [],
   "source": [
    "def create_document_term_matrix(sen,vectorizer):\n",
    "  doc_term_matrix=vectorizer.fit_transform(sen)\n",
    "  return DataFrame(doc_term_matrix.toarray(), columns=vectorizer.get_feature_names())\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kPdXonU2e9Ew"
   },
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "28eA0yL0lFL7"
   },
   "outputs": [],
   "source": [
    "def calculate_cosine_similarity(df_list,sentences,question):\n",
    "  a=[]\n",
    "  for i in range(len(df_list)-1):\n",
    "    sim=1 - spatial.distance.cosine(df_list[i], question)\n",
    "    t=(sim,sentences[i])\n",
    "    a.append(t)\n",
    "  a.sort(reverse=True)\n",
    "  n=[]\n",
    "  for i in range(3):\n",
    "    n.append(a[i][1])\n",
    "    #print(\"*\",n[i])\n",
    "   \n",
    "    \n",
    "  return n  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fA81IVTvdGz6"
   },
   "source": [
    "**Function to classify questions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "tRYoXgLYlNSD"
   },
   "outputs": [],
   "source": [
    "def questiontype( question):\n",
    "        questiontags = ['WP','WDT','WP$','WRB']\n",
    "        question_POS = pos_tag(word_tokenize(question.lower()))\n",
    "        \n",
    "        question_Tags=[]\n",
    "        for token in question_POS:\n",
    "            if token[1] in questiontags:\n",
    "              question_Tags.append(token)\n",
    "                \n",
    "                \n",
    "        if len(question_Tags)==1 and question_Tags[0][0]!= 'what' :\n",
    "          return True\n",
    "        else:\n",
    "          return False  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vKwWilpbfigw"
   },
   "source": [
    "**Function to find the most relevant sentence using n-gram similarity **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "8Cli_jJ0lONW"
   },
   "outputs": [],
   "source": [
    "from nltk.util import ngrams\n",
    "def n_gram_similarity(question,n):\n",
    "  q=list(ngrams(word_tokenize(question.lower()),1))\n",
    "  a=0\n",
    "  b=0\n",
    "  c=0\n",
    "  t=[]\n",
    "  for i in q:\n",
    "    if i in list(ngrams(word_tokenize(n[0].lower()),1)):\n",
    "      a=a+1\n",
    "  for i in q:\n",
    "    if i in list(ngrams(word_tokenize(n[1].lower()),1)):\n",
    "      b=b+1\n",
    "  for i in q:\n",
    "    if i in list(ngrams(word_tokenize(n[2].lower()),1)):\n",
    "      c=c+1        \n",
    "  d=max(a,b,c)\n",
    "  if a == d:\n",
    "    t.append(n[0])\n",
    "  if b == d:\n",
    "    t.append(n[1]) \n",
    "  if c ==d:\n",
    "    t.append(n[2])\n",
    "  print()  \n",
    "  #print(\"Selected Sentence:\",t[0])  \n",
    "  return t  \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vaFGtZwff2Cr"
   },
   "source": [
    "**answertype:**Determines the type of entity that has to be returned, performs entity ranking if multiple entities a present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "xKBe8u5slTdA"
   },
   "outputs": [],
   "source": [
    "def answertype(question):\n",
    "  nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "  if (questiontype(question)):\n",
    "    t='DESCRIPTIVE'\n",
    "    flag=0\n",
    "    word=word_tokenize(question.lower())\n",
    "  \n",
    "    if 'who' in word:\n",
    "      t='PERSON'\n",
    "    elif 'where' in word:\n",
    "      t='GPE'\n",
    "    elif 'how' in word and 'many' in word and  'age' in word or 'duration' in word or 'long' in word or 'days'in word or 'years' in word or'months' in word:\n",
    "      t='DATE' \n",
    "    elif 'how' in word and 'many' in word :\n",
    "       t = 'CARDINAL'  \n",
    "    elif 'when' in word  or 'age' in word or 'period' in word or 'duration' in word  or 'old' in word or 'long' in word:\n",
    "      t='DATE'\n",
    "    elif 'how' in word  and 'long' in word or 'often' or 'age' in word or 'years' in word:\n",
    "      t='DATE' \n",
    "    elif 'what' in word and 'time' in word or 'duration' in word or 'period' in  'word'  :\n",
    "      t='DATE' \n",
    "    i=len(df_list)-1  \n",
    "    n=calculate_cosine_similarity(df_list, sentences,df_list[i])\n",
    "    n=n_gram_similarity(question,n)\n",
    "    #print(\"Most relevant sentence\", n[0])\n",
    "    #print(\"ANSWER TYPE:\",t)\n",
    "    key = n[0]\n",
    "    spdoc = nlp(key)\n",
    "    entity_type=[]\n",
    "    for ent in spdoc.ents:\n",
    "       if ent.label_ == t:\n",
    "          entity_type.append(ent.text)\n",
    "    if len(entity_type) == 1:\n",
    "      #print(\"ANSWER TYPE:\", t)\n",
    "      print(\"ANSWER:\", entity_type[0])  \n",
    "    if len(entity_type) == 0:\n",
    "      #print(\"ANSWER TYPE:\", t) \n",
    "      print(n[0])\n",
    "    if len(entity_type) > 1:\n",
    "      #print(\"Answer Type:\",t)  \n",
    "      key_question = question\n",
    "      q=[]\n",
    "      spdoc = nlp(key_question)\n",
    "      for ent in spdoc:\n",
    "        if ent.pos_ == 'NOUN' or ent.pos_ =='ADJ' :\n",
    "          q.append(ent.text)\n",
    "  \n",
    "      key_answer = n[0]\n",
    "      a = []\n",
    "      spd = nlp(key)\n",
    "      for ent in spd:\n",
    "        if ent.pos_ == 'NOUN'or ent.pos_ =='ADJ' :\n",
    "          a.append(ent.text)\n",
    "  #s=[sentence.index(i) for i in t]\n",
    "      s=[]\n",
    "      w=[]\n",
    "      for i in entity_type:\n",
    "       s.append(n[0].index(i))\n",
    "      for i in range(len(s)):\n",
    "        w.append(0)\n",
    "\n",
    "    \n",
    "      for i in q:\n",
    "        try:\n",
    "           factor= n[0].index(i)\n",
    "           for j in range(len(s)):\n",
    "              w[j]=w[j]+(abs(s[j]-factor))\n",
    "        except:\n",
    "           continue    \n",
    "      m=min(w)\n",
    "      u=[]\n",
    "      for i in range(len(s)):\n",
    "        if w[i] == m:\n",
    "           #print(entity_type[i])\n",
    "           u.append(entity_type[i])\n",
    "      print(\"ANSWER:\",u[0])     \n",
    "      \n",
    "\n",
    "  \n",
    "\n",
    "    \n",
    "  else:\n",
    "    t='DESCRIPTIVE'\n",
    "    #print(\"ANSWER TYPE:\",t)\n",
    "    i=len(df_list)-1  \n",
    "    n=calculate_cosine_similarity(df_list, sentences,df_list[i])\n",
    "    #n = n_gram_similarity(question, n)\n",
    "    for j in n:\n",
    "         print(j) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21852,
     "status": "ok",
     "timestamp": 1668922117889,
     "user": {
      "displayName": "farrikh alzami",
      "userId": "11964535993149439504"
     },
     "user_tz": -420
    },
    "id": "m1r9nOcqlezX",
    "outputId": "4fdbddbf-827e-4dcd-c8ea-13390a4df7f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUESTION: How many cases have been reported and how many deaths have occured in various countries?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/masaboe/miniconda3/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ANSWER: more than 8.75 million\n",
      "\n",
      "\n",
      "ANSWER: more than 463,000\n",
      "\n",
      "QUESTION: What are the common symptoms and how long should I wash my hands?\n",
      "As is common with infections, there is a delay between the moment a person is first infected and the time he or she develops symptoms.\n",
      "Common symptoms include fever, cough, fatigue, shortness of breath, and loss of smell and taste.\n",
      "It is most contagious during the first three days after the onset of symptoms, although spread is possible before symptoms appear, and from people who do not show symptoms.\n",
      "\n",
      "\n",
      "The CDC also recommends that individuals wash hands often with soap and water for at least 20 seconds, especially after going to the toilet or when hands are visibly dirty, before eating and after blowing one's nose, coughing or sneezing.\n",
      "\n",
      "QUESTION: How many people have recovered till now and how many cases have been reported?\n",
      "\n",
      "ANSWER: More than 4.33 million\n",
      "\n",
      "\n",
      "ANSWER: more than 8.75 million\n",
      "\n",
      "QUESTION: How far apart should people stay and how long should I wash my hands ?\n",
      "\n",
      "Distancing guidelines also include that people stay at least 6 feet (1.8 m) apart.\n",
      "\n",
      "\n",
      "The CDC also recommends that individuals wash hands often with soap and water for at least 20 seconds, especially after going to the toilet or when hands are visibly dirty, before eating and after blowing one's nose, coughing or sneezing.\n",
      "\n",
      "QUESTION: When was the first case discovered and where was the virus first identified?\n",
      "\n",
      "ANSWER: 17th November 2019\n",
      "\n",
      "\n",
      "ANSWER: Wuhan\n",
      "\n",
      "QUESTION: When was the first case discoverd  ?\n",
      "\n",
      "ANSWER: 17th November 2019\n",
      "\n",
      "QUESTION: Where was the virus first identified?\n",
      "\n",
      "ANSWER: Wuhan\n",
      "\n",
      "QUESTION: When was the virus first identified?\n",
      "\n",
      "ANSWER: December 2019\n",
      "\n",
      "QUESTION: When did the first case occur in Delhi?\n",
      "\n",
      "ANSWER: 2nd March\n",
      "\n",
      "QUESTION: How many days is the incubation period of the virus?\n",
      "\n",
      "ANSWER: five or six days\n",
      "\n",
      "QUESTION: When was COVID-19 declared a health emergency?\n",
      "\n",
      "ANSWER: 30 January 2020\n",
      "\n",
      "QUESTION: When was COVID-19 declared a pandemic?\n",
      "\n",
      "ANSWER: 11 March 2020\n",
      "\n",
      "QUESTION: How apart should people stay?\n",
      "\n",
      "Distancing guidelines also include that people stay at least 6 feet (1.8 m) apart.\n",
      "\n",
      "QUESTION: How many people have recovered till now?\n",
      "\n",
      "ANSWER: More than 4.33 million\n",
      "\n",
      "QUESTION: How many cases have been reported?\n",
      "\n",
      "ANSWER: more than 8.75 million\n",
      "\n",
      "QUESTION: How many deaths have occured in various countries?\n",
      "\n",
      "ANSWER: more than 463,000\n",
      "\n",
      "QUESTION: In how many World Health Organization zones local transmission has occuerd?\n",
      "\n",
      "ANSWER: six\n",
      "\n",
      "QUESTION: Cases have been reported in how many countries?\n",
      "\n",
      "ANSWER: 188\n",
      "\n",
      "QUESTION: How many countries have reported cases?\n",
      "\n",
      "ANSWER: 188\n",
      "\n",
      "QUESTION: How long should I wash my hands?\n",
      "\n",
      "The CDC also recommends that individuals wash hands often with soap and water for at least 20 seconds, especially after going to the toilet or when hands are visibly dirty, before eating and after blowing one's nose, coughing or sneezing.\n",
      "\n",
      "QUESTION: What are the common symptoms of COVID-19?\n",
      "Fever is the most common symptom of COVID-19, but is highly variable in severity and presentation, with some older, immunocompromised, or critically ill people not having fever at all.\n",
      "As is common with infections, there is a delay between the moment a person is first infected and the time he or she develops symptoms.\n",
      "Common symptoms include fever, cough, fatigue, shortness of breath, and loss of smell and taste.\n",
      "\n",
      "QUESTION: What type of masks should I wear?\n",
      "Health officials also stated that medical-grade face masks, such as N95 masks, should only be used by healthcare workers, first responders, and those who directly care for infected individuals.\n",
      "Several countries have recommended that healthy individuals wear face masks or cloth face coverings (like scarves or bandanas) at least in certain public settings, including China, Hong Kong, Spain, Italy, Russia, and the United States.\n",
      "Those diagnosed with coronavirus or who believe they may be infected are advised by the CDC to stay home except to get medical care, call ahead before visiting a healthcare provider, wear a face mask before entering the healthcare provider's office and when in any room or vehicle with another person, cover coughs and sneezes with a tissue, regularly wash hands with soap and water and avoid sharing personal household items.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#from textblob import TextBlob\n",
    "\n",
    "question=[\"How many cases have been reported and how many deaths have occured in various countries?\",\"What are the common symptoms and how long should I wash my hands?\",\"How many people have recovered till now and how many cases have been reported?\",\"How far apart should people stay and how long should I wash my hands ?\",\"When was the first case discovered and where was the virus first identified?\",\"When was the first case discoverd  ?\",\"Where was the virus first identified?\",\"When was the virus first identified?\",\"When did the first case occur in Delhi?\",\"How many days is the incubation period of the virus?\",\"When was COVID-19 declared a health emergency?\",\"When was COVID-19 declared a pandemic?\",\"How apart should people stay?\",\"How many people have recovered till now?\",\"How many cases have been reported?\",\"How many deaths have occured in various countries?\",\"In how many World Health Organization zones local transmission has occuerd?\",\"Cases have been reported in how many countries?\",\"How many countries have reported cases?\",\"How long should I wash my hands?\",\"What are the common symptoms of COVID-19?\",\"What type of masks should I wear?\"]\n",
    "\n",
    "\n",
    "for j in question:\n",
    "  #j=TextBlob(j)\n",
    "  #j=str(j.correct())\n",
    " \n",
    "  qq=[]\n",
    "  qp=[]\n",
    "  que=sent_tokenize(j)\n",
    "  \n",
    "  qq.append(que)\n",
    "  qp.append(j)\n",
    "  questiontags = ['WP','WDT','WP$','WRB']\n",
    "  question_POS = pos_tag(word_tokenize(j.lower()))\n",
    "        \n",
    "  question_Tags=[]\n",
    "  for token in question_POS:\n",
    "      if token[1] in questiontags:\n",
    "          question_Tags.append(token)\n",
    "  \n",
    " \n",
    "  if len(question_Tags)>1:\n",
    "     if ' and ' in j :\n",
    "       pos=j.lower().find('and')\n",
    "       qq=[]\n",
    "       qp=[]\n",
    "       qp.append(j[:pos])\n",
    "       qp.append(j[pos+1:])\n",
    "       qq.append(sent_tokenize(j[:pos])) \n",
    "       qq.append(sent_tokenize(j[pos+1:])) \n",
    "  \n",
    "     \n",
    "               \n",
    "  \n",
    "\n",
    "  \n",
    "  print(\"QUESTION:\",j)\n",
    "  for k in range(len(qp)):   \n",
    "       \n",
    "\n",
    "\n",
    "    sentences=sent_tokenize(s)\n",
    "    #q contains a list of cleaned sentence tokens of question\n",
    "    q=get_cleaned_sentences(qq[k],stopwords=True)\n",
    "    #preprocessed contains a list of cleaned sentence tokens of the reference text\n",
    "    preprocessed=get_cleaned_sentences(sentences,stopwords=True)\n",
    "  \n",
    "    preprocessed.append(q[0])\n",
    "    i=len(preprocessed)-1\n",
    "    \n",
    "  \n",
    "    tfidf_vect=TfidfVectorizer()\n",
    "    df=create_document_term_matrix(preprocessed,tfidf_vect) \n",
    "    df_list = df.values.tolist()\n",
    "    answertype(qp[k])\n",
    "    print()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HTgV5KvWgjaJ"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
